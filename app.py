import os
import time
import json
import hashlib
import requests
import jwt  # PyJWT
import pandas as pd
import streamlit as st

# ============================================================
# PassKit é‡è¤‡ ID æœå°‹ / å›æ”¶åˆ†é…å·¥å…·
# - æŸ¥è©¢ï¼šç”¨ person.displayName æ‰¾ memberId
# - æ‰¾å‡ºï¼šåŒåå¤šç­† / æœªæ‰¾åˆ°
# - å›æ”¶ï¼šPASS_ISSUED ä¸” meta.cardNumber ç‚ºç©ºï¼ˆæˆ– NULLï¼‰
# - åˆ†é…ï¼šæŠŠå›æ”¶çš„ memberId æ”¹åçµ¦ missing åå–®ï¼ˆPUT æ›´æ–°ï¼‰
# - é˜²é‡è¤‡å›æ”¶ï¼šå¯«å…¥ meta.recycleLockï¼ˆå¯é—œé–‰/å¯æ”¹ keyï¼‰
# ============================================================

# ----------------------------
# Page
# ----------------------------
st.set_page_config(
    page_title="PassKit é‡è¤‡ ID æœå°‹ / å›æ”¶åˆ†é…å·¥å…·",
    page_icon="â™»ï¸",
    layout="wide",
)
st.title("â™»ï¸ PassKit é‡è¤‡ ID æœå°‹ / å›æ”¶åˆ†é…å·¥å…·")
st.caption("å›æ”¶æ¢ä»¶ï¼šPASS_ISSUED + meta.cardNumber ç‚ºç©ºï¼ˆæˆ– NULLï¼‰ã€‚å…ˆ Dry-run é è¦½ mappingï¼Œå† Apply æ‰¹æ¬¡ PUTã€‚")

# ----------------------------
# Config helpers
# ----------------------------
def get_config(key: str, default: str | None = None) -> str | None:
    val = st.secrets.get(key) if hasattr(st, "secrets") else None
    if val is None:
        val = os.environ.get(key, default)
    if val is None:
        return None
    return str(val).replace("\\n", "\n").strip()

PK_API_KEY = get_config("PK_API_KEY")
PK_API_SECRET = get_config("PK_API_SECRET")
PK_API_PREFIX = get_config("PK_API_PREFIX", "https://api.pub1.passkit.io")
PROGRAM_ID = get_config("PROGRAM_ID")

missing_cfg = [k for k, v in {
    "PK_API_KEY": PK_API_KEY,
    "PK_API_SECRET": PK_API_SECRET,
    "PK_API_PREFIX": PK_API_PREFIX,
    "PROGRAM_ID": PROGRAM_ID
}.items() if not v]

if missing_cfg:
    st.error(f"âŒ ç¼ºå°‘è¨­å®šï¼š{', '.join(missing_cfg)}ï¼ˆè«‹åœ¨ .env æˆ– Streamlit Secrets è£œä¸Šï¼‰")
    st.stop()

# ----------------------------
# JWT auth (PassKit style)
# ----------------------------
def make_jwt_for_body(body_text: str) -> str:
    now = int(time.time())
    payload = {"uid": PK_API_KEY, "iat": now, "exp": now + 600}
    if body_text:
        payload["signature"] = hashlib.sha256(body_text.encode("utf-8")).hexdigest()

    token = jwt.encode(payload, PK_API_SECRET, algorithm="HS256")
    if isinstance(token, bytes):
        token = token.decode("utf-8")
    return token

def _handle_resp_errors(resp: requests.Response) -> None:
    if resp.status_code == 404:
        raise RuntimeError("404 Not Foundï¼šå¤šåŠæ˜¯ API Prefixï¼ˆpub1/pub2ï¼‰æˆ– endpoint path ç”¨éŒ¯ã€‚")
    if resp.status_code in (401, 403):
        raise RuntimeError(
            f"Auth å¤±æ•—ï¼ˆ{resp.status_code}ï¼‰ï¼šè«‹ç¢ºèª PK_API_KEY/PK_API_SECRETã€ä»¥åŠ API Prefixï¼ˆpub1/pub2ï¼‰ã€‚"
        )
    if not resp.ok:
        raise RuntimeError(f"HTTP {resp.status_code}: {resp.text[:1200]}")

# ----------------------------
# PassKit API calls
# ----------------------------
def post_list_members(filters_payload: dict) -> list[dict]:
    """
    POST {PK_API_PREFIX}/members/member/list/{PROGRAM_ID}
    PassKit list APIs sometimes return NDJSON (one JSON per line)
    """
    url = f"{PK_API_PREFIX.rstrip('/')}/members/member/list/{PROGRAM_ID}"
    body_text = json.dumps({"filters": filters_payload}, separators=(",", ":"), ensure_ascii=False)

    token = make_jwt_for_body(body_text)
    headers = {"Authorization": token, "Content-Type": "application/json"}

    resp = requests.post(url, headers=headers, data=body_text, timeout=30)
    _handle_resp_errors(resp)

    text = (resp.text or "").strip()
    if not text:
        return []

    items: list[dict] = []
    lines = [ln for ln in text.split("\n") if ln.strip()]
    for ln in lines:
        try:
            items.append(json.loads(ln))
        except json.JSONDecodeError:
            items = [json.loads(text)]
            break
    return items

def put_update_member(payload: dict) -> dict:
    """
    PUT {PK_API_PREFIX}/members/member
    """
    url = f"{PK_API_PREFIX.rstrip('/')}/members/member"
    body_text = json.dumps(payload, separators=(",", ":"), ensure_ascii=False)

    token = make_jwt_for_body(body_text)
    headers = {"Authorization": token, "Content-Type": "application/json"}

    resp = requests.put(url, headers=headers, data=body_text, timeout=30)
    _handle_resp_errors(resp)

    try:
        return resp.json()
    except Exception:
        return {"ok": True, "text": resp.text[:1200]}

# ----------------------------
# Data helpers
# ----------------------------
def extract_member_obj(item: dict) -> dict | None:
    member = item.get("result") or item.get("member") or item
    return member if isinstance(member, dict) else None

def _get_meta_container(member: dict) -> dict:
    # ä½ ç’°å¢ƒå›å‚³æ˜¯ metaï¼›ä¹Ÿåšç›¸å®¹ï¼ˆè‹¥æ—¥å¾Œè®Šæˆ metaData/metadataï¼‰
    meta = member.get("meta")
    if not isinstance(meta, dict):
        meta = member.get("metaData")
    if not isinstance(meta, dict):
        meta = member.get("metadata")
    return meta if isinstance(meta, dict) else {}

def is_blank(v) -> bool:
    if v is None:
        return True
    s = str(v).strip()
    return (s == "") or (s.upper() == "NULL")

def normalize_name(s: str, remove_spaces: bool) -> str:
    s = (s or "").strip()
    if remove_spaces:
        s = s.replace(" ", "")
    return s

# âœ… ä¾ä½ æˆªåœ–ï¼šField Key = meta.cardNumber â†’ meta dict key = "cardNumber"
CARDNUMBER_META_DICT_KEY = "cardNumber"     # meta["cardNumber"]
CARDNUMBER_FILTER_FIELD_1 = "meta.cardNumber"
CARDNUMBER_FILTER_FIELD_2 = "cardNumber"    # æŸäº›å¾Œç«¯ä¹Ÿåƒé€™ç¨®

def extract_member_rows(list_response_items: list[dict], search_name: str, max_hits: int, lock_key: str) -> list[dict]:
    rows = []
    for item in list_response_items:
        member = extract_member_obj(item)
        if not member:
            continue

        person = member.get("person") or {}
        meta = _get_meta_container(member)

        display_name = (person.get("displayName") or "").strip()
        member_id = (member.get("id") or "").strip()
        pass_status = (member.get("passStatus") or "").strip()

        card_number = meta.get(CARDNUMBER_META_DICT_KEY)
        card_number = "" if card_number is None else str(card_number).strip()

        lock_val = meta.get(lock_key) if lock_key else None
        lock_val = "" if lock_val is None else str(lock_val).strip()

        created = member.get("created") or member.get("createdAt") or member.get("createdOn") or ""
        updated = member.get("updated") or member.get("updatedAt") or member.get("updatedOn") or ""

        if display_name and member_id:
            rows.append({
                "æœå°‹å§“å": search_name,
                "displayName": display_name,
                "memberId": member_id,
                "passStatus": pass_status,
                "meta.cardNumber": card_number,
                f"meta.{lock_key}" if lock_key else "meta.lock": lock_val,
                "created": str(created),
                "updated": str(updated),
            })

        if len(rows) >= max_hits:
            break
    return rows

def search_by_display_name(name: str, max_hits: int, operator: str, lock_key: str) -> list[dict]:
    filters = {
        "limit": min(int(max_hits), 1000),
        "offset": 0,
        "filterGroups": [{
            "condition": "AND",
            "fieldFilters": [{
                "filterField": "displayName",
                "filterValue": name,
                "filterOperator": operator,  # eq / like
            }]
        }]
    }
    items = post_list_members(filters)
    return extract_member_rows(items, name, max_hits=max_hits, lock_key=lock_key)

# ----------------------------
# Recycle logic
# ----------------------------
def is_recyclable_row(row: dict, lock_col: str) -> bool:
    # ä½ çš„å›æ”¶æ¢ä»¶ï¼šPASS_ISSUED + meta.cardNumber ç©º
    # å†åŠ ä¸€æ¢ï¼šlock ä¹Ÿå¿…é ˆç©ºï¼ˆé¿å…å·²åˆ†é…éçš„å†è¢«å›æ”¶ï¼‰
    return (
        (row.get("passStatus") == "PASS_ISSUED")
        and is_blank(row.get("meta.cardNumber"))
        and (lock_col not in row or is_blank(row.get(lock_col)))
    )

def choose_duplicate_recycle_candidates(df_hits: pd.DataFrame, lock_col: str) -> pd.DataFrame:
    """
    å¾åŒåå¤šç­†ä¸­æŒ‘å›æ”¶å€™é¸ï¼š
      - æ¯å€‹ displayName ä¿ç•™æœ€æ–° 1 ç­†ï¼ˆupdated/created ç›¡é‡åˆ¤æ–·ï¼‰
      - å…¶é¤˜è‹¥ PASS_ISSUED + meta.cardNumber ç©º + lock ç©º â†’ å›æ”¶æ± 
    """
    if df_hits.empty:
        return df_hits.iloc[0:0].copy()

    work = df_hits.copy()
    for col in ["updated", "created"]:
        if col in work.columns:
            work[col] = pd.to_datetime(work[col], errors="coerce")

    candidates = []
    for _, g in work.groupby("displayName", dropna=False):
        if len(g) <= 1:
            continue

        # newest first
        if g["updated"].notna().any() or g["created"].notna().any():
            g_sorted = g.sort_values(["updated", "created"], ascending=[False, False], na_position="last")
        else:
            g_sorted = g.copy()

        # keep newest (first)
        rest = g_sorted.iloc[1:]
        for _, r in rest.iterrows():
            if is_recyclable_row(r.to_dict(), lock_col=lock_col):
                candidates.append(r.to_dict())

    return pd.DataFrame(candidates) if candidates else work.iloc[0:0].copy()

def list_recycle_pool_global(limit: int, offset: int, lock_key: str) -> list[dict]:
    """
    å…¨åŸŸå›æ”¶æ± ï¼š
      passStatus == PASS_ISSUED
      meta.cardNumber == NULL
    æ³¨æ„ï¼šæ˜¯å¦æ”¯æ´å° meta æ¬„ä½åš NULL filter å–æ±ºæ–¼å¾Œç«¯ã€‚
    """
    def _call(field_name: str) -> list[dict]:
        filters = {
            "limit": min(int(limit), 1000),
            "offset": int(offset),
            "orderBy": "created",
            "orderAsc": True,
            "filterGroups": [{
                "condition": "AND",
                "fieldFilters": [
                    {"filterField": "passStatus", "filterValue": "PASS_ISSUED", "filterOperator": "eq"},
                    {"filterField": field_name, "filterValue": "NULL", "filterOperator": "eq"},
                ]
            }]
        }
        items = post_list_members(filters)

        pool = []
        for item in items:
            member = extract_member_obj(item)
            if not member:
                continue
            meta = _get_meta_container(member)
            mid = (member.get("id") or "").strip()
            ps = (member.get("passStatus") or "").strip()

            card = meta.get(CARDNUMBER_META_DICT_KEY)
            lock = meta.get(lock_key) if lock_key else None

            if mid and ps == "PASS_ISSUED" and is_blank(card) and is_blank(lock):
                pool.append({
                    "memberId": mid,
                    "passStatus": ps,
                    "meta.cardNumber": "" if card is None else str(card).strip(),
                    f"meta.{lock_key}" if lock_key else "meta.lock": "" if lock is None else str(lock).strip(),
                    "created": str(member.get("created") or ""),
                })
        return pool

    # å…ˆç”¨å®Œæ•´ Field Keyï¼ˆä½ å¾Œå° Data Fields é¡¯ç¤ºçš„ï¼‰
    pool = _call(CARDNUMBER_FILTER_FIELD_1)
    if pool:
        return pool
    # fallback
    return _call(CARDNUMBER_FILTER_FIELD_2)

def build_update_payload(member_id: str, new_display_name: str, lock_key: str, write_lock: bool) -> dict:
    """
    åˆ†é…æ™‚ PUT æ›´æ–°ï¼š
      - person.displayName = new_display_name
      - meta.recycleLock = timestampï¼ˆé è¨­é–‹ï¼‰
    é‡è¦ï¼šä¸è¦å¯« TEMP åˆ° meta.cardNumberï¼ˆå®ƒæ˜¯æœƒé¡¯ç¤ºçš„æ¬„ä½ï¼‰
    """
    payload = {"programId": PROGRAM_ID, "id": member_id, "person": {"displayName": new_display_name}}
    if write_lock and lock_key:
        payload["meta"] = {lock_key: str(int(time.time()))}
    return payload

def put_reassign(member_id: str, new_display_name: str, lock_key: str, write_lock: bool) -> tuple[dict, bool]:
    """
    å…ˆç”¨ nested å½¢å¼ï¼ˆperson/metaï¼‰ã€‚
    è‹¥æ›´æ–°å« lock å¤±æ•—ï¼Œæœƒ fallbackï¼šåªæ›´æ–° displayNameï¼ˆä¸å¯« lockï¼‰ã€‚
    å›å‚³ï¼š(resp, lock_written)
    """
    new_display_name = (new_display_name or "").strip()

    # 1) try with lock
    if write_lock and lock_key:
        payload_with_lock = build_update_payload(member_id, new_display_name, lock_key, write_lock=True)
        try:
            return put_update_member(payload_with_lock), True
        except Exception:
            # å¯èƒ½å¾Œç«¯ä¸å…è¨±æœªçŸ¥ meta keyï¼šæ”¹èµ°ä¸å¯« lock
            pass

    # 2) update displayName only (nested)
    payload_no_lock = {"programId": PROGRAM_ID, "id": member_id, "person": {"displayName": new_display_name}}
    try:
        return put_update_member(payload_no_lock), False
    except Exception:
        # 3) dot-key fallback
        payload_dot = {"programId": PROGRAM_ID, "id": member_id, "person.displayName": new_display_name}
        return put_update_member(payload_dot), False

# ----------------------------
# UI - Search
# ----------------------------
st.session_state.setdefault("hits_rows", [])
st.session_state.setdefault("missing_names", [])

with st.form("search_form"):
    input_text = st.text_area(
        "æ¯è¡Œä¸€å€‹ displayNameï¼ˆperson.displayNameï¼‰â€” æœ€å¤š 150 è¡Œ",
        height=220,
        placeholder="MEIHUA LEE\nHSIUTING CHOU\nKUANYEN LEE\n...",
    )

    colA, colB, colC, colD, colE = st.columns([1, 1, 1, 1, 2])
    with colA:
        max_hits = st.number_input("åŒåæœ€å¤šå›å‚³ç­†æ•¸", min_value=1, max_value=150, value=10, step=1)
    with colB:
        operator = st.selectbox("æ¯”å°æ–¹å¼", options=["eq", "like"], index=0)
    with colC:
        throttle = st.number_input("æ¯æ¬¡ API é–“éš”ç§’æ•¸", min_value=0.0, max_value=2.0, value=0.15, step=0.05)
    with colD:
        remove_spaces = st.checkbox("æŸ¥è©¢å‰ç§»é™¤ç©ºæ ¼", value=False)
    with colE:
        lock_key = st.text_input("é˜²é‡è¤‡å›æ”¶ lock keyï¼ˆå­˜æ–¼ metaï¼‰", value="recycleLock")
        st.caption("å»ºè­°ä¿ç•™ï¼šç”¨ meta.recycleLock æ¨™è¨˜å·²åˆ†é…ï¼Œé¿å…åŒä¸€å¼µå¡è¢«å†æ¬¡å›æ”¶ã€‚")

    submitted = st.form_submit_button("Search")

if submitted:
    raw_names = [n for n in (input_text or "").splitlines() if n.strip()]
    names = [normalize_name(n, remove_spaces=remove_spaces) for n in raw_names if normalize_name(n, remove_spaces)]
    if not names:
        st.warning("è«‹å…ˆè²¼ä¸Šè‡³å°‘ä¸€è¡Œå§“åã€‚")
        st.stop()

    if len(names) > 150:
        st.warning(f"ä½ è²¼äº† {len(names)} è¡Œï¼Œç³»çµ±åªæœƒå–å‰ 150 è¡Œã€‚")
        names = names[:150]

    all_rows: list[dict] = []
    missing: list[str] = []

    prog = st.progress(0.0)
    status = st.empty()

    for i, name in enumerate(names, start=1):
        status.info(f"æŸ¥è©¢ä¸­ {i}/{len(names)}ï¼š{name}")
        try:
            rows = search_by_display_name(name, max_hits=int(max_hits), operator=operator, lock_key=lock_key)
            if rows:
                all_rows.extend(rows)
            else:
                missing.append(name)
        except Exception as e:
            st.error(f"âŒ æŸ¥è©¢å¤±æ•—ï¼š{name} â†’ {e}")
            missing.append(name)

        prog.progress(i / len(names))
        if float(throttle) > 0:
            time.sleep(float(throttle))

    status.empty()
    prog.empty()

    st.session_state["hits_rows"] = all_rows
    st.session_state["missing_names"] = missing

    st.success(f"å®Œæˆï¼šæŸ¥è©¢ {len(names)} ç­†ï¼Œå‘½ä¸­ {len(all_rows)} ç­†ï¼›æœªæ‰¾åˆ° {len(missing)} ç­†ã€‚")

# ----------------------------
# Render results
# ----------------------------
hits_rows = st.session_state.get("hits_rows") or []
missing_names = st.session_state.get("missing_names") or []
lock_col = f"meta.{lock_key}" if lock_key else "meta.lock"

if hits_rows:
    df_hits = pd.DataFrame(hits_rows)
    cols_order = [c for c in ["æœå°‹å§“å", "displayName", "memberId", "passStatus", "meta.cardNumber", lock_col, "created", "updated"] if c in df_hits.columns]
    df_hits = df_hits[cols_order].copy()

    left, right = st.columns([2, 1], gap="large")
    with left:
        st.subheader("å‘½ä¸­æ¸…å–®")
        st.dataframe(df_hits, use_container_width=True, height=420)
        st.download_button(
            "ä¸‹è¼‰å‘½ä¸­ CSV",
            data=df_hits.to_csv(index=False).encode("utf-8-sig"),
            file_name="passkit_member_hits.csv",
            mime="text/csv",
        )

    with right:
        st.subheader("é‡è¤‡çµ±è¨ˆï¼ˆæŒ‰ displayNameï¼‰")
        dup_counts = (
            df_hits.groupby("displayName")["memberId"]
            .nunique()
            .reset_index(name="åŒå memberId æ•¸é‡")
            .sort_values("åŒå memberId æ•¸é‡", ascending=False)
        )
        dup_only = dup_counts[dup_counts["åŒå memberId æ•¸é‡"] > 1].copy()
        st.metric("åŒåé‡è¤‡åç¨±æ•¸", int(len(dup_only)))
        st.dataframe(dup_only, use_container_width=True, height=260)

        st.subheader("æœªæ‰¾åˆ°åå–®ï¼ˆmissingï¼‰")
        if missing_names:
            st.write("\n".join(missing_names))
        else:
            st.info("æ²’æœ‰ missingã€‚")

elif submitted:
    st.info("æ²’æœ‰å‘½ä¸­è³‡æ–™ï¼ˆhits ç‚º 0ï¼‰ã€‚è‹¥ä½ ç¢ºèªè³‡æ–™å­˜åœ¨ï¼Œè«‹æª¢æŸ¥ PROGRAM_ID / API Prefix / operatorã€‚")

# ----------------------------
# Recycle & assign
# ----------------------------
st.divider()
st.header("â™»ï¸ å›æ”¶æ±  â†’ åˆ†é…çµ¦ missingï¼ˆPASS_ISSUED + meta.cardNumber ç©ºï¼‰")

if not missing_names:
    st.info("ç›®å‰æ²’æœ‰ missing åå–®ï¼Œå› æ­¤ä¸éœ€è¦åˆ†é…å›æ”¶æ± ã€‚")
else:
    st.warning(
        "âš ï¸ é‡è¦æé†’ï¼šä½ ç›®å‰æ²’æœ‰ã€Pass URL æ˜¯å¦æ›¾ç™¼é€/å¤–æµã€çš„ç´€éŒ„ã€‚\n"
        "PASS_ISSUED ä»£è¡¨ URL å·²å­˜åœ¨ï¼›å³ä½¿æœª installedï¼Œè‹¥ URL æ›¾å¤–æµï¼Œä½ æŠŠ memberId æ”¹åçµ¦åˆ¥äººï¼Œç­‰æ–¼è½‰æ‰‹ã€‚\n"
        "æ­¤å·¥å…·ä¾ä½ çš„è¦æ±‚ï¼šä»¥ã€PASS_ISSUED + meta.cardNumber ç©ºã€åšå›æ”¶æ¢ä»¶ï¼Œä¸¦æä¾› Dry-runâ†’Apply å…©æ®µå¼é¿å…èª¤æ“ä½œã€‚"
    )

    mode = st.radio(
        "å›æ”¶æ± ä¾†æº",
        options=[
            "A) å…¨åŸŸå›æ”¶æ± ï¼šPASS_ISSUED + meta.cardNumber ç‚ºç©ºï¼ˆä¸ä¾è³´é‡è¤‡æŸ¥è©¢ï¼‰",
            "B) åŒåé‡è¤‡å›æ”¶ï¼šæ¯å€‹ displayName ä¿ç•™æœ€æ–° 1 ç­†ï¼Œå…¶é¤˜ç¬¦åˆæ¢ä»¶è€…å›æ”¶ï¼ˆæ›´è²¼è¿‘ä½ æˆªåœ–æƒ…å¢ƒï¼‰",
        ],
        index=1,
    )

    col1, col2, col3, col4 = st.columns([1, 1, 1, 2])
    with col1:
        assign_limit = st.number_input("æœ€å¤šåˆ†é…ç­†æ•¸", min_value=1, max_value=5000, value=min(300, len(missing_names)), step=10)
    with col2:
        apply_throttle = st.number_input("æ¯æ¬¡ PUT é–“éš”ç§’æ•¸", min_value=0.0, max_value=2.0, value=0.2, step=0.05)
    with col3:
        write_lock = st.checkbox("Apply æ™‚å¯«å…¥ meta.lockï¼ˆå»ºè­°é–‹ï¼‰", value=True)
    with col4:
        st.caption("ä¸æœƒå¯«å…¥ cardNumberï¼ˆé¿å…é¡¯ç¤ºçµ¦å®¢äººï¼‰ï¼›æ”¹ç”¨ meta.recycleLock æ¨™è¨˜å·²åˆ†é…ï¼Œé˜²æ­¢å†æ¬¡è¢«å›æ”¶ã€‚")

    recycle_ids: list[str] = []

    if mode.startswith("A)"):
        st.subheader("A) å–å¾—å…¨åŸŸå›æ”¶æ± ")
        pool_limit = st.number_input("å›æ”¶æ± æ’ˆå–ä¸Šé™", min_value=10, max_value=1000, value=300, step=50)
        fetch_pool = st.button("å–å¾—å›æ”¶æ± ï¼ˆAï¼‰", type="secondary")
        if fetch_pool:
            try:
                pool = list_recycle_pool_global(limit=int(pool_limit), offset=0, lock_key=lock_key)
                st.session_state["recycle_pool_A"] = pool
                st.success(f"å›æ”¶æ± å–å¾—å®Œæˆï¼š{len(pool)} ç­†ã€‚")
            except Exception as e:
                st.error(f"âŒ å–å¾—å›æ”¶æ± å¤±æ•—ï¼š{e}")

        pool = st.session_state.get("recycle_pool_A") or []
        if pool:
            df_pool = pd.DataFrame(pool)
            st.dataframe(df_pool, use_container_width=True, height=260)
            recycle_ids = [x["memberId"] for x in pool if x.get("memberId")]
        else:
            st.info("å°šæœªå–å¾—å›æ”¶æ± ï¼Œæˆ–å›æ”¶æ± ç‚ºç©ºï¼ˆå¯èƒ½æ˜¯å¾Œç«¯ä¸æ”¯æ´å° meta.cardNumber åš NULL filterï¼‰ã€‚")

    else:
        st.subheader("B) å¾åŒåé‡è¤‡ä¸­æŒ‘å›æ”¶å€™é¸ï¼ˆä¿ç•™æœ€æ–° 1 ç­†ï¼Œå…¶é¤˜ PASS_ISSUED + meta.cardNumber ç©ºè€…å›æ”¶ï¼‰")
        if not hits_rows:
            st.info("ä½ éœ€è¦å…ˆ Search å–å¾—å‘½ä¸­è³‡æ–™ï¼Œæ‰èƒ½ä½¿ç”¨ B æ¨¡å¼ã€‚")
        else:
            df_hits2 = pd.DataFrame(hits_rows)
            cand_df = choose_duplicate_recycle_candidates(df_hits2, lock_col=lock_col)
            if cand_df.empty:
                st.info("æ‰¾ä¸åˆ°ç¬¦åˆå›æ”¶æ¢ä»¶çš„åŒåå€™é¸ï¼ˆPASS_ISSUED + meta.cardNumber ç©º + lock ç©ºï¼‰ã€‚")
            else:
                st.success(f"æ‰¾åˆ°å¯å›æ”¶å€™é¸ï¼š{len(cand_df)} ç­†ã€‚")
                show_cols = [c for c in ["displayName", "memberId", "passStatus", "meta.cardNumber", lock_col, "created", "updated"] if c in cand_df.columns]
                st.dataframe(cand_df[show_cols], use_container_width=True, height=260)
                recycle_ids = [str(x).strip() for x in cand_df["memberId"].tolist() if str(x).strip()]

    # dedupe keep order
    seen = set()
    recycle_ids = [x for x in recycle_ids if not (x in seen or seen.add(x))]

    st.subheader("ğŸ“Œ Dry-runï¼šç”¢ç”Ÿåˆ†é… mappingï¼ˆä¸æœƒå¯«å…¥ï¼‰")
    max_assign = int(min(assign_limit, len(missing_names), len(recycle_ids)))
    if max_assign <= 0:
        st.info("ç›®å‰ç„¡æ³•ç”¢ç”Ÿ mappingï¼šå¯èƒ½æ˜¯å›æ”¶æ± ç‚ºç©ºï¼Œæˆ– missing ç‚ºç©ºã€‚")
    else:
        mapping = [{"new_displayName": missing_names[i], "recycled_memberId": recycle_ids[i]} for i in range(max_assign)]
        df_map = pd.DataFrame(mapping)
        st.dataframe(df_map, use_container_width=True, height=260)

        st.download_button(
            "ä¸‹è¼‰ mapping CSVï¼ˆDry-runï¼‰",
            data=df_map.to_csv(index=False).encode("utf-8-sig"),
            file_name="recycle_mapping_dryrun.csv",
            mime="text/csv",
        )

        st.divider()
        st.subheader("âœ… Applyï¼šä¾ mapping æ‰¹æ¬¡æ›´æ–°ï¼ˆPUT /members/memberï¼‰")

        ack = st.checkbox(
            "æˆ‘äº†è§£é¢¨éšªï¼šPASS_ISSUED ä»å¯èƒ½å·²è¢«åˆ†äº«ã€‚è‹¥å›æ”¶çš„ memberId/URL æ›¾å¤–æµï¼Œæ›´æ–°å¾Œæœƒè®“èˆŠ URL æŒ‡å‘æ–°æœƒå“¡è³‡æ–™ï¼ˆç­‰æ–¼è½‰æ‰‹ï¼‰ã€‚",
            value=False,
        )
        do_apply = st.button("Apply æ‰¹æ¬¡æ›´æ–°", type="primary", disabled=not ack)

        if do_apply:
            ok_rows = []
            fail_rows = []

            prog2 = st.progress(0.0)
            status2 = st.empty()

            for i, row in enumerate(mapping, start=1):
                new_name = row["new_displayName"]
                member_id = row["recycled_memberId"]

                status2.info(f"æ›´æ–°ä¸­ {i}/{len(mapping)}ï¼š{member_id} â†’ {new_name}")

                try:
                    resp, lock_written = put_reassign(
                        member_id=member_id,
                        new_display_name=new_name,
                        lock_key=lock_key,
                        write_lock=write_lock,
                    )
                    ok_rows.append({
                        "memberId": member_id,
                        "new_displayName": new_name,
                        "result": "OK",
                        "lockWritten": bool(lock_written),
                        "resp": str(resp)[:500],
                    })
                except Exception as e:
                    fail_rows.append({
                        "memberId": member_id,
                        "new_displayName": new_name,
                        "result": "FAIL",
                        "error": str(e)[:1200],
                    })

                prog2.progress(i / len(mapping))
                if float(apply_throttle) > 0:
                    time.sleep(float(apply_throttle))

            status2.empty()
            prog2.empty()

            st.success(f"å®Œæˆï¼šæˆåŠŸ {len(ok_rows)} ç­†ï¼›å¤±æ•— {len(fail_rows)} ç­†ã€‚")

            if ok_rows:
                df_ok = pd.DataFrame(ok_rows)
                st.subheader("æˆåŠŸæ¸…å–®")
                st.dataframe(df_ok, use_container_width=True, height=260)
                st.download_button(
                    "ä¸‹è¼‰æˆåŠŸ CSV",
                    data=df_ok.to_csv(index=False).encode("utf-8-sig"),
                    file_name="recycle_apply_success.csv",
                    mime="text/csv",
                )

            if fail_rows:
                df_fail = pd.DataFrame(fail_rows)
                st.subheader("å¤±æ•—æ¸…å–®")
                st.dataframe(df_fail, use_container_width=True, height=260)
                st.download_button(
                    "ä¸‹è¼‰å¤±æ•— CSV",
                    data=df_fail.to_csv(index=False).encode("utf-8-sig"),
                    file_name="recycle_apply_failed.csv",
                    mime="text/csv",
                )
